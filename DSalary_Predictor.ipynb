{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22782e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import urllib.parse\n",
    "import time\n",
    "import string\n",
    "import pyperclip\n",
    "import quopri\n",
    "from bs4 import BeautifulSoup\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "import psycopg2\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ee5d9",
   "metadata": {},
   "source": [
    "# 1.Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e158b05b",
   "metadata": {},
   "source": [
    "(1). Download LinkedIn Search Results Webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d7337a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an automatic process to download the job search pages in Linkedin\n",
    "def auto_download_search(url,file_name):\n",
    "    pyautogui.hotkey('ctrl', '2') # switch Google Chrome tabs\n",
    "    time.sleep(1)\n",
    "    \n",
    "    pyautogui.click(207,55) # click the browser's address bar.\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    pyautogui.hotkey('ctrl', 'a') # select all content in the address bar.\n",
    "    pyperclip.copy(url) # copy the url\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    pyautogui.hotkey('ctrl', 'v') # paste the url\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    pyautogui.hotkey('enter') # access the url\n",
    "    time.sleep(10)\n",
    "    \n",
    "    pyautogui.click(882,1023)\n",
    "    pyautogui.mouseDown() # scroll down the page to look through all job posts\n",
    "    time.sleep(10)\n",
    "    pyautogui.mouseUp()# release the left mouse button\n",
    "    \n",
    "    pyautogui.hotkey('ctrl', 's') # save the page to local path\n",
    "    time.sleep(2)\n",
    "    pyperclip.copy(file_name) # copy the file name\n",
    "    pyautogui.hotkey('ctrl', 'v') # paste the file name\n",
    "    time.sleep(2)\n",
    "    pyautogui.hotkey('enter') # save the page with given name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430ed6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a process to look through all the pages of search results\n",
    "def search_page_download(num = 0):\n",
    "    for i in range(0,1000,25):\n",
    "        url = f\"https://www.linkedin.com/jobs/search/?currentJobId=3733476715&f_SB2=1&f_TPR=r2592000&geoId=103644278&keywords=data%20scientist&location=United%20States&origin=JOB_SEARCH_PAGE_JOB_FILTER&refresh=true&sortBy=R&spellCorrectionEnabled=true&start={i}\"\n",
    "        file_name = f\"data_science_job_{num + int(i/25)}.mhtml\"\n",
    "        auto_download_search(url, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bb42a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download all pages to collect 1000 job posts related to data science\n",
    "search_page_download(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a54abc",
   "metadata": {},
   "source": [
    "(2). Extract Individual Job Post URLs from LinkedIn Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f4a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract urls of job posts from all the pages\n",
    "def job_url(file_path):\n",
    "    urls = []\n",
    "    # Open the MHTML file in binary mode and parse it\n",
    "    with open(file_path, 'rb') as file:\n",
    "        msg = BytesParser(policy=policy.default).parse(file)\n",
    "\n",
    "    # Decode the HTML part correctly\n",
    "    html_part = None\n",
    "    for part in msg.walk():\n",
    "        content_type = part.get_content_type()\n",
    "        if content_type == 'text/html':\n",
    "            html_part = part.get_payload(decode=True)\n",
    "            break\n",
    "    \n",
    "    # parse the HTML\n",
    "    charset = 'utf-8'\n",
    "    decoded_html = html_part.decode(charset)\n",
    "    soup = BeautifulSoup(decoded_html, 'html.parser')\n",
    "    jobs = soup.find(class_ = \"scaffold-layout__list-container\")\n",
    "    job_info = jobs.find_all(class_ = \"disabled ember-view job-card-container__link job-card-list__title\")\n",
    "    # extract the url for each job post\n",
    "    for i in job_info:\n",
    "        url = i['href']\n",
    "        urls.append(url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43066379",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "job_urls = {}\n",
    "i = 0\n",
    "path = \"D:/Study Abroad/course/DSCI441/project/webpages\"\n",
    "\n",
    "# get the urls of all job posts from the local job pages\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        urls = job_url(file_path)\n",
    "        for url in urls:\n",
    "            job_urls[i] = {}\n",
    "            job_urls[i][\"url\"] = url\n",
    "            job_urls[i][\"status\"] = 0\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ad7da",
   "metadata": {},
   "source": [
    "(3). Download Job Post Details Webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "388fe551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually login the linkedin website\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.linkedin.com/home\")\n",
    "\n",
    "# wait enough time to log in manually\n",
    "time.sleep(20)  \n",
    "\n",
    "# save the cookies to a file after login\n",
    "pickle.dump(driver.get_cookies(), open(\"D:/Study Abroad/course/DSCI441/project/cookies.pkl\", \"wb\"))\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56ea62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use selenium webdriver to iterate all the job pages\n",
    "# set the options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# load the previously saved cookies\n",
    "cookies = pickle.load(open(\"D:/Study Abroad/course/DSCI441/project/cookies.pkl\", \"rb\"))\n",
    "\n",
    "# iterate all job post pages and download them to local path\n",
    "for i in range(0,1000):\n",
    "    index = i\n",
    "    value = job_urls[index]\n",
    "    \n",
    "    # open a new driver after iterating the job post pages for 20 times in order to save memory\n",
    "    if index % 20 == 0:\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(\"https://www.linkedin.com/home\")\n",
    "        time.sleep(4)\n",
    "        \n",
    "        # load the cookies to the driver\n",
    "        for cookie in cookies:\n",
    "            driver.add_cookie(cookie)\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # get the url for job post\n",
    "    url = value[\"url\"]\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # use the aria-label to locate the button\n",
    "    button_aria_label = \"Click to see more description\"\n",
    "    try:\n",
    "        # Wait up to 10 seconds for the button to be clickable\n",
    "        button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, f\"//button[@aria-label='{button_aria_label}']\")))\n",
    "        # click the button \"Show More\" to show the entire job description\n",
    "        button.click()\n",
    "        \n",
    "        time.sleep(2) # wait up for all information displayed\n",
    "        \n",
    "    except Exception as e:\n",
    "        break # if failed, jump to the next iteration\n",
    "    \n",
    "    pyautogui.hotkey('ctrl', 's') # save the page to local path\n",
    "    time.sleep(2)\n",
    "    \n",
    "    file_name = \"data_scientist_job_post_\" + str(index)\n",
    "    pyperclip.copy(file_name) # copy the file name\n",
    "    \n",
    "    pyautogui.hotkey('ctrl', 'v') # paste the file name\n",
    "    time.sleep(2)\n",
    "    \n",
    "    if index % 20 == 0:\n",
    "        pyautogui.hotkey('tab')  # select the save type\n",
    "        time.sleep(1)\n",
    "\n",
    "        pyautogui.hotkey('down')\n",
    "        time.sleep(1)\n",
    "\n",
    "        pyautogui.hotkey('up')  # save file to mhtml\n",
    "        time.sleep(1)\n",
    "\n",
    "        pyautogui.hotkey('enter') # confirm the file tyep\n",
    "        time.sleep(1)\n",
    "    \n",
    "    pyautogui.hotkey('enter') # save\n",
    "    time.sleep(np.random.randint(1,4)) # wait for random time\n",
    "    \n",
    "    if index % 20 == 19:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1e598",
   "metadata": {},
   "source": [
    "(4). Extract Key Information from Job Posting Webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba830fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize all job_type, remote, and experience\n",
    "JOB_TYPE = [\"Full-time\",\"Part-time\",\"Contract\",\"Temporary\",\"Internship\",\"Other\"]\n",
    "REMOTE_TYPE = [\"On-site\",\"Remote\",\"Hybrid\"]\n",
    "EXPERIENCE_TYPE = [\"Internship\",\"Entry level\",\"Associate\",\"Mid-Senior level\",\"Director\",\"Executive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d0907e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to extract job_type, remote, and experience information\n",
    "def extract_info(info, options):\n",
    "    for i in options:\n",
    "        if i in info:\n",
    "            return i\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41dab625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables to store the details of all the jobs\n",
    "indice = []\n",
    "titles = []\n",
    "companies = []\n",
    "locations = []\n",
    "job_types = []\n",
    "remotes = []\n",
    "experiences = []\n",
    "salaries = []\n",
    "company_sizes = []\n",
    "fields = []\n",
    "job_descriptions = []\n",
    "skills_posted = []\n",
    "skills_associated = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f645d32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the urls of all job posts from the local job pages\n",
    "path = \"D:/Study Abroad/course/DSCI441/project/jobposts\"\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        # Open the MHTML file in binary mode and parse it\n",
    "        with open(file_path, 'rb') as file:\n",
    "            msg = BytesParser(policy=policy.default).parse(file)\n",
    "\n",
    "        # Decode the HTML part correctly\n",
    "        html_part = None\n",
    "        for part in msg.walk():\n",
    "            content_type = part.get_content_type()\n",
    "            if content_type == 'text/html':\n",
    "                html_part = part.get_payload(decode=True)\n",
    "                break\n",
    "\n",
    "        # parse the HTML\n",
    "        charset = 'utf-8'\n",
    "        decoded_html = html_part.decode(charset)\n",
    "        soup = BeautifulSoup(decoded_html, 'html.parser')\n",
    "        \n",
    "        # extract the index\n",
    "        index = file_path.replace(\".mhtml\",\"\").split(\"_\")[-1]\n",
    "        indice.append(index)\n",
    "        \n",
    "        # extract title\n",
    "        title = soup.find(class_=\"t-24 t-bold job-details-jobs-unified-top-card__job-title\").contents[0].strip()\n",
    "        titles.append(title)\n",
    "        \n",
    "        # extract company and location\n",
    "        company_location = soup.find(class_=\"job-details-jobs-unified-top-card__primary-description-without-tagline mb2\").text.strip()\n",
    "        company = company_location.split('·')[0].strip()\n",
    "        location = company_location.split('·')[1].strip()\n",
    "        companies.append(company)\n",
    "        locations.append(location)\n",
    "        \n",
    "        # extract job_type, remote, experience, and salary\n",
    "        salary_jobtype_Remote_Experience = soup.find(class_=\"job-details-jobs-unified-top-card__job-insight job-details-jobs-unified-top-card__job-insight--highlight\").text\n",
    "        job_type = extract_info(salary_jobtype_Remote_Experience,JOB_TYPE)\n",
    "        remote = extract_info(salary_jobtype_Remote_Experience,REMOTE_TYPE)\n",
    "        experience = extract_info(salary_jobtype_Remote_Experience,EXPERIENCE_TYPE)\n",
    "        salary = salary_jobtype_Remote_Experience.strip().split('\\n')[0]\n",
    "        job_types.append(job_type)\n",
    "        remotes.append(remote)\n",
    "        experiences.append(experience)\n",
    "        salaries.append(salary)\n",
    "        \n",
    "        # extract company size and field\n",
    "        companysize_field = soup.find_all(class_ = \"job-details-jobs-unified-top-card__job-insight\")[1].text.split('·')\n",
    "        company_size = companysize_field[0].strip()\n",
    "        company_sizes.append(company_size)\n",
    "        if len(companysize_field)>1: \n",
    "            field = companysize_field[1].strip() \n",
    "        else:\n",
    "            field = None\n",
    "        fields.append(field)\n",
    "        \n",
    "        # extract the job description\n",
    "        job_description = soup.find(class_ = \"jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch\").text.strip()\n",
    "        job_descriptions.append(job_description)\n",
    "\n",
    "        # extract the associated skills and skills added by job posters\n",
    "        skill_posted = [item.text for item in soup.find_all(class_=\"pt5\")[1].find_all(\"a\",class_=\"app-aware-link job-details-how-you-match__skills-item-subtitle t-14 overflow-hidden\")]\n",
    "        skill_associated = [item.text for item in soup.find_all(class_=\"pt5\")[1].find_all(\"a\",class_=\"app-aware-link job-details-how-you-match__skills-section-descriptive-skill t-14\")]\n",
    "        skills_posted.append(skill_posted)\n",
    "        skills_associated.append(skill_associated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "011a3fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame((titles,companies,locations,job_types,remotes,experiences,salaries,company_sizes,fields,job_descriptions,skills_posted,skills_associated,indice)).T\n",
    "df.columns=[\"Job_Title\",\"Company_Name\",\"Location\",\"Job_Type\",\"Remote\",\"Experience_Level\",\"Salary\",\"Company_Size\",\"Field\",\"Job_Description\",\"Posted_Skills\",\"Associated_Skills\",\"Files\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7084a5",
   "metadata": {},
   "source": [
    "(5). Store the information into postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f11a231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_database(df,connection):\n",
    "    cursor = connection.cursor()\n",
    "    data = df.drop('Files',axis = 1).copy()\n",
    "    data = data.fillna(\"Unknown\")\n",
    "    # insert into database\n",
    "    try:\n",
    "        for fields in data.values:\n",
    "            insert_query = \"INSERT INTO t_ds_job_info\"\n",
    "            insert_columns = '(\"' + '\",\"'.join(data.columns) + '\")'\n",
    "            insert_values = \"(\" \n",
    "            for field in fields:\n",
    "                insert_values += \"'\" + str(field).replace(\"'\",\"\").replace('\"','') + \"',\"\n",
    "            insert_values = insert_values[:-1]\n",
    "            insert_values +=  \")\"\n",
    "            insert_query = insert_query + insert_columns + \" VALUES \" + insert_values\n",
    "            cursor.execute(insert_query)\n",
    "            connection.commit()\n",
    "    except:\n",
    "        print(insert_query)\n",
    "\n",
    "    # Close the connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    \n",
    "# a function to extract data from database\n",
    "def query(SQL,connection):\n",
    "    df = pd.read_sql(SQL,connection)\n",
    "    connection.close()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dfab48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the connection\n",
    "connection = psycopg2.connect(\n",
    "    dbname=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "# save the information\n",
    "insert_database(df,connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b94fd4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiang Gao\\AppData\\Local\\Temp\\ipykernel_7004\\3009979463.py:27: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(SQL,connection)\n"
     ]
    }
   ],
   "source": [
    "connection = psycopg2.connect(\n",
    "    dbname=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "# save the information\n",
    "SQL = 'select distinct \"Job_Title\",\"Company_Name\" ,\"Location\",\"Job_Type\",\"Remote\",\"Experience_Level\",\"Salary\",\"Company_Size\" ,\"Field\" ,\"Job_Description\" ,\"Posted_Skills\",\"Associated_Skills\" from t_ds_job_info'\n",
    "df = query(SQL,connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a76ba370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job_Type</th>\n",
       "      <th>Remote</th>\n",
       "      <th>Experience_Level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Company_Size</th>\n",
       "      <th>Field</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>Posted_Skills</th>\n",
       "      <th>Associated_Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist II, Amazon Business Ops Analytics</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$111,600/yr - $212,800/yr</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>About the job\\n            \\n \\nDescriptionWe ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Machine Learning · Extract, Transform, Load (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CACI International Inc</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$82,100/yr - $172,400/yr</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>About the job\\n            \\n \\nJob Category: ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Logistic Regression · Computer Vision · Machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist with Security Clearance</td>\n",
       "      <td>ClearanceJobs</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$155,000/yr</td>\n",
       "      <td>11-50 employees</td>\n",
       "      <td>Defense and Space Manufacturing</td>\n",
       "      <td>About the job\\n            \\n \\nAward Winning ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Data Mining · HTML · Data Analytics · SQL · P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sr Data Scientist, ProServe GenAI - Open Reqs</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$127,300/yr - $247,600/yr</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>About the job\\n            \\n \\nDescriptionAre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Machine Learning · Artificial Intelligence (A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Insight Global</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Contract</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$70/hr - $80/hr</td>\n",
       "      <td>1,001-5,000 employees</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>About the job\\n            \\n \\nSr. Data Scien...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Python (Programming Language) · Applied Machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Mission Solution SAFe Shared Services- Data Sc...</td>\n",
       "      <td>CACI International Inc</td>\n",
       "      <td>Aurora, CO</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$104,200/yr - $229,200/yr</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>About the job\\n            \\n \\nJob Category: ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[R (Programming Language) · Big Data Analytics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>Huntsville, AL</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>$73,000/yr - $166,000/yr</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>About the job\\n            \\n \\nJob Number: R0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Data Mining · Analytics · Data Analytics · Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Data Scientist, Analytics - Tiktok</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>$144,000/yr - $240,000/yr</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>Entertainment Providers</td>\n",
       "      <td>About the job\\n            \\n \\nResponsibiliti...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Data Visualization · Natural Language Process...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Data Scientist, Mid</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>Smith, IN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>$73,000/yr - $166,000/yr</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>About the job\\n            \\n \\nJob Number: R0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Python (Programming Language) · Analytics · D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>Tempe, AZ</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$130,000/yr - $140,000/yr</td>\n",
       "      <td>201-500 employees</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>About the job\\n            \\n \\nPrincipal Data...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Python (Programming Language) · SQL · Snowflake]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Job_Title  \\\n",
       "0     Data Scientist II, Amazon Business Ops Analytics   \n",
       "1                                       Data Scientist   \n",
       "2               Data Scientist with Security Clearance   \n",
       "3        Sr Data Scientist, ProServe GenAI - Open Reqs   \n",
       "4                                       Data Scientist   \n",
       "..                                                 ...   \n",
       "616  Mission Solution SAFe Shared Services- Data Sc...   \n",
       "617                                     Data Scientist   \n",
       "618                 Data Scientist, Analytics - Tiktok   \n",
       "619                                Data Scientist, Mid   \n",
       "620                           Principal Data Scientist   \n",
       "\n",
       "                  Company_Name         Location   Job_Type   Remote  \\\n",
       "0                       Amazon    Arlington, VA  Full-time  Unknown   \n",
       "1       CACI International Inc       Denver, CO  Full-time  Unknown   \n",
       "2                ClearanceJobs    Arlington, VA  Full-time   Hybrid   \n",
       "3    Amazon Web Services (AWS)  Santa Clara, CA  Full-time  Unknown   \n",
       "4               Insight Global      Seattle, WA   Contract  On-site   \n",
       "..                         ...              ...        ...      ...   \n",
       "616     CACI International Inc       Aurora, CO  Full-time  On-site   \n",
       "617        Booz Allen Hamilton   Huntsville, AL  Full-time  Unknown   \n",
       "618                     TikTok     San Jose, CA  Full-time  Unknown   \n",
       "619        Booz Allen Hamilton        Smith, IN  Full-time  Unknown   \n",
       "620                    Harnham        Tempe, AZ  Full-time   Hybrid   \n",
       "\n",
       "     Experience_Level                     Salary           Company_Size  \\\n",
       "0    Mid-Senior level  $111,600/yr - $212,800/yr      10,001+ employees   \n",
       "1    Mid-Senior level   $82,100/yr - $172,400/yr      10,001+ employees   \n",
       "2    Mid-Senior level                $155,000/yr        11-50 employees   \n",
       "3    Mid-Senior level  $127,300/yr - $247,600/yr      10,001+ employees   \n",
       "4    Mid-Senior level            $70/hr - $80/hr  1,001-5,000 employees   \n",
       "..                ...                        ...                    ...   \n",
       "616  Mid-Senior level  $104,200/yr - $229,200/yr      10,001+ employees   \n",
       "617           Unknown   $73,000/yr - $166,000/yr      10,001+ employees   \n",
       "618           Unknown  $144,000/yr - $240,000/yr      10,001+ employees   \n",
       "619           Unknown   $73,000/yr - $166,000/yr      10,001+ employees   \n",
       "620  Mid-Senior level  $130,000/yr - $140,000/yr      201-500 employees   \n",
       "\n",
       "                               Field  \\\n",
       "0               Software Development   \n",
       "1      IT Services and IT Consulting   \n",
       "2    Defense and Space Manufacturing   \n",
       "3      IT Services and IT Consulting   \n",
       "4            Staffing and Recruiting   \n",
       "..                               ...   \n",
       "616    IT Services and IT Consulting   \n",
       "617    IT Services and IT Consulting   \n",
       "618          Entertainment Providers   \n",
       "619    IT Services and IT Consulting   \n",
       "620          Staffing and Recruiting   \n",
       "\n",
       "                                       Job_Description Posted_Skills  \\\n",
       "0    About the job\\n            \\n \\nDescriptionWe ...            []   \n",
       "1    About the job\\n            \\n \\nJob Category: ...            []   \n",
       "2    About the job\\n            \\n \\nAward Winning ...            []   \n",
       "3    About the job\\n            \\n \\nDescriptionAre...            []   \n",
       "4    About the job\\n            \\n \\nSr. Data Scien...            []   \n",
       "..                                                 ...           ...   \n",
       "616  About the job\\n            \\n \\nJob Category: ...            []   \n",
       "617  About the job\\n            \\n \\nJob Number: R0...            []   \n",
       "618  About the job\\n            \\n \\nResponsibiliti...            []   \n",
       "619  About the job\\n            \\n \\nJob Number: R0...            []   \n",
       "620  About the job\\n            \\n \\nPrincipal Data...            []   \n",
       "\n",
       "                                     Associated_Skills  \n",
       "0    [Machine Learning · Extract, Transform, Load (...  \n",
       "1    [Logistic Regression · Computer Vision · Machi...  \n",
       "2    [Data Mining · HTML · Data Analytics · SQL · P...  \n",
       "3    [Machine Learning · Artificial Intelligence (A...  \n",
       "4    [Python (Programming Language) · Applied Machi...  \n",
       "..                                                 ...  \n",
       "616  [R (Programming Language) · Big Data Analytics...  \n",
       "617  [Data Mining · Analytics · Data Analytics · Pa...  \n",
       "618  [Data Visualization · Natural Language Process...  \n",
       "619  [Python (Programming Language) · Analytics · D...  \n",
       "620  [Python (Programming Language) · SQL · Snowflake]  \n",
       "\n",
       "[621 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa66b3f",
   "metadata": {},
   "source": [
    "# 2.Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c065dce",
   "metadata": {},
   "source": [
    "#### (1). Reformat numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ba3c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to extract state from location\n",
    "def location_to_state(value):\n",
    "    area_state_dict = {\"United States\":\"Unknown\",\n",
    "                 \"Los Angeles Metropolitan Area\": \"CA\",\n",
    "                 \"Greater Seattle Area\": \"WA\",\n",
    "                 \"New York City Metropolitan Area\": \"NY\",\n",
    "                 \"Greater Minneapolis-St. Paul Area\": \"MN\",\n",
    "                 \"San Francisco Bay Area\": \"CA\",\n",
    "                 \"Miami-Fort Lauderdale Area\": \"FL\",\n",
    "                 \"Atlanta Metropolitan Area\": \"GA\",\n",
    "                 \"Washington DC-Baltimore Area\": \"DC\",\n",
    "                 \"Charlotte Metro\": \"NC\",\n",
    "                 \"Greater Phoenix Area\": \"AZ\",\n",
    "                 \"Dallas-Fort Worth Metroplex\": \"TX\",\n",
    "                 \"Greater Richmond Region\": \"VA\" ,\n",
    "                 \"San Diego Metropolitan Area\": \"CA\",\n",
    "                 \"Greater Boston\": \"MA\",\n",
    "                 \"Oregon Metropolitan Area\":\"OR\",\n",
    "                 'Alabama': 'AL',\n",
    "                 'Alaska': 'AK',\n",
    "                 'Arizona': 'AZ',\n",
    "                 'Arkansas': 'AR',\n",
    "                 'California': 'CA',\n",
    "                 'Colorado': 'CO',\n",
    "                 'Connecticut': 'CT',\n",
    "                 'Delaware': 'DE',\n",
    "                 'Florida': 'FL',\n",
    "                 'Georgia': 'GA',\n",
    "                 'Hawaii': 'HI',\n",
    "                 'Idaho': 'ID',\n",
    "                 'Illinois': 'IL',\n",
    "                 'Indiana': 'IN',\n",
    "                 'Iowa': 'IA',\n",
    "                 'Kansas': 'KS',\n",
    "                 'Kentucky': 'KY',\n",
    "                 'Louisiana': 'LA',\n",
    "                 'Maine': 'ME',\n",
    "                 'Maryland': 'MD',\n",
    "                 'Massachusetts': 'MA',\n",
    "                 'Michigan': 'MI',\n",
    "                 'Minnesota': 'MN',\n",
    "                 'Mississippi': 'MS',\n",
    "                 'Missouri': 'MO',\n",
    "                 'Montana': 'MT',\n",
    "                 'Nebraska': 'NE',\n",
    "                 'Nevada': 'NV',\n",
    "                 'New Hampshire': 'NH',\n",
    "                 'New Jersey': 'NJ',\n",
    "                 'New Mexico': 'NM',\n",
    "                 'New York': 'NY',\n",
    "                 'North Carolina': 'NC',\n",
    "                 'North Dakota': 'ND',\n",
    "                 'Ohio': 'OH',\n",
    "                 'Oklahoma': 'OK',\n",
    "                 'Oregon': 'OR',\n",
    "                 'Pennsylvania': 'PA',\n",
    "                 'Rhode Island': 'RI',\n",
    "                 'South Carolina': 'SC',\n",
    "                 'South Dakota': 'SD',\n",
    "                 'Tennessee': 'TN',\n",
    "                 'Texas': 'TX',\n",
    "                 'Utah': 'UT',\n",
    "                 'Vermont': 'VT',\n",
    "                 'Virginia': 'VA',\n",
    "                 'Washington': 'WA',\n",
    "                 'West Virginia': 'WV',\n",
    "                 'Wisconsin': 'WI',\n",
    "                 'Wyoming': 'WY'}\n",
    "    \n",
    "    if \",\" not in value:\n",
    "        state = area_state_dict.get(value.strip(),\"Unknown\")\n",
    "    elif len(value.split(\",\")[1].strip())>2 and value.split(\",\")[1].strip()!=\"United States\":\n",
    "        state = area_state_dict.get(value.split(',')[1].strip())\n",
    "    elif len(value.split(\",\")[1].strip())>2 and value.split(\",\")[1].strip()==\"United States\":\n",
    "        state = area_state_dict.get(value.split(',')[0].strip(),\"Unknown\")\n",
    "    else:\n",
    "        state = value.split(',')[1].strip()\n",
    "    \n",
    "    return state\n",
    "\n",
    "# define function to extract the salary range\n",
    "def salary_to_annual_salary_range(value):\n",
    "    if \"-\" not in value and \"/hr\" in value:\n",
    "        value = value.replace(\"/hr\",\"\")\n",
    "        value = value.replace(\"$\",\"\") \n",
    "        value = value.replace(\",\",\"\")\n",
    "        upper = float(value) * 40 * 52\n",
    "        lower = float(value) * 40 * 52\n",
    "        \n",
    "    elif \"-\" not in value and \"/yr\" in value:\n",
    "        value = value.replace(\"/yr\",\"\")\n",
    "        value = value.replace(\"$\",\"\") \n",
    "        value = value.replace(\",\",\"\")\n",
    "        value = value.replace(\"Up to \",\"\")\n",
    "        upper = float(value)\n",
    "        lower = float(value)\n",
    "    \n",
    "    elif \"-\" in value and \"/hr\" in value:\n",
    "        value = value.replace(\"/hr\",\"\")\n",
    "        value = value.replace(\"$\",\"\") \n",
    "        value = value.replace(\",\",\"\")\n",
    "        upper = float(value.split(\"-\")[0].strip())  * 40 * 52\n",
    "        lower = float(value.split(\"-\")[1].strip())  * 40 * 52\n",
    "    \n",
    "    elif \"-\" in value and \"/month\" in value:\n",
    "        value = value.replace(\"/month\",\"\")\n",
    "        value = value.replace(\"$\",\"\") \n",
    "        value = value.replace(\",\",\"\")\n",
    "        upper = float(value.split(\"-\")[0].strip()) * 12\n",
    "        lower = float(value.split(\"-\")[1].strip()) * 12\n",
    "\n",
    "    elif \"-\" in value and \"/yr\" in value:\n",
    "        value = value.replace(\"/yr\",\"\")\n",
    "        value = value.replace(\"$\",\"\") \n",
    "        value = value.replace(\",\",\"\")\n",
    "        upper = float(value.split(\"-\")[0].strip())\n",
    "        lower = float(value.split(\"-\")[1].split(\"+\")[0].strip())\n",
    "    return upper, lower\n",
    "\n",
    "# define function to quantize the avg company size \n",
    "def avg_company_size(value):\n",
    "    dict_company_size = {'10,001+ employees':  20000,\n",
    "                         '5,001-10,000 employees': 7500,\n",
    "                         '1,001-5,000 employees': 3000,\n",
    "                         '501-1,000 employees': 750,\n",
    "                         '201-500 employees': 350,\n",
    "                         '51-200 employees': 125,\n",
    "                         '11-50 employees' : 30,\n",
    "                         '1-10 employees' : 5                       \n",
    "                        }\n",
    "    company_size = dict_company_size.get(value,0)\n",
    "    return company_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62d3a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the state information\n",
    "# drop the city and area information since it is too detailed and may cause overfitting after one-hot encoding\n",
    "df[\"State\"] = df[\"Location\"].apply(location_to_state)\n",
    "\n",
    "# extract the range of salary\n",
    "df[\"Salary_Lower\"] = df[\"Salary\"].apply(salary_to_annual_salary_range).apply(lambda x:x[0])\n",
    "df[\"Salary_Upper\"] = df[\"Salary\"].apply(salary_to_annual_salary_range).apply(lambda x:x[1])\n",
    "\n",
    "# quantize the Company_Size using the avg value\n",
    "df['Company_Size'] = df['Company_Size'].apply(avg_company_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1916eb1",
   "metadata": {},
   "source": [
    "#### (2). Handle text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae206c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to identify the english words included in the job title\n",
    "def words_identification_title(value):\n",
    "    punctuations = string.punctuation\n",
    "    # Replace each punctuation mark with a space\n",
    "    for p in punctuations:\n",
    "        value = value.replace(p, \" \")\n",
    "    value = value.split(\" \")\n",
    "    value = [word.strip() for word in value]\n",
    "    \n",
    "    return value\n",
    "\n",
    "# define function to identify the english words included in the job description\n",
    "def words_identification_description(value):\n",
    "    english_words = set(words.words())\n",
    "    tokens = word_tokenize(value)\n",
    "    identified_words = [token.strip() for token in tokens if token.lower() in english_words]\n",
    "    return identified_words\n",
    "\n",
    "# define function to identify the skills in the Posted_Skills\n",
    "def posted_skillset(value):\n",
    "    value = value.replace('[','')\n",
    "    value = value.replace(']','')\n",
    "    value = value.replace(', and',',')\n",
    "    skillset = value.split(\",\")\n",
    "    skillset = [skill.strip() for skill in skillset]\n",
    "    if skillset == ['']:\n",
    "        skillset = []\n",
    "        \n",
    "    return skillset\n",
    "\n",
    "# define function to identify the skills in the Associated_Skills\n",
    "def associated_skillset(value):\n",
    "    value = value.replace('[','')\n",
    "    value = value.replace(']','')\n",
    "    skillset = value.split('·')\n",
    "    skillset = [skill.strip() for skill in skillset]\n",
    "    if skillset == ['']:\n",
    "        skillset = []\n",
    "    return skillset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd628591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Xiang\n",
      "[nltk_data]     Gao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Xiang\n",
      "[nltk_data]     Gao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# extract words from job title\n",
    "df['Job_Title_Words'] = df['Job_Title'].apply(words_identification_title)\n",
    "\n",
    "# extract words from job description\n",
    "df['Job_Description_Words'] = df['Job_Description'].apply(words_identification_description)\n",
    "\n",
    "# extract posted skills\n",
    "df['Posted_Skills'] = df['Posted_Skills'].apply(posted_skillset)\n",
    "\n",
    "# extract associated skills\n",
    "df['Associated_Skills'] = df['Associated_Skills'].apply(associated_skillset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc6f9f3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title_Words</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Job_Type</th>\n",
       "      <th>Remote</th>\n",
       "      <th>Experience_Level</th>\n",
       "      <th>Company_Size</th>\n",
       "      <th>Field</th>\n",
       "      <th>Job_Description_Words</th>\n",
       "      <th>Posted_Skills</th>\n",
       "      <th>Associated_Skills</th>\n",
       "      <th>Salary_Lower</th>\n",
       "      <th>Salary_Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Data, Scientist, II, , Amazon, Business, Ops,...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>VA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>20000</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>[About, the, job, are, seeking, a, Data, Scien...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Machine Learning, Extract, Transform, Load (E...</td>\n",
       "      <td>111600.0</td>\n",
       "      <td>212800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Data, Scientist]</td>\n",
       "      <td>CACI International Inc</td>\n",
       "      <td>CO</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>20000</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>[About, the, job, Job, Category, Type, Full, C...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Logistic Regression, Computer Vision, Machine...</td>\n",
       "      <td>82100.0</td>\n",
       "      <td>172400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Data, Scientist, with, Security, Clearance]</td>\n",
       "      <td>ClearanceJobs</td>\n",
       "      <td>VA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>30</td>\n",
       "      <td>Defense and Space Manufacturing</td>\n",
       "      <td>[About, the, job, Award, Winning, Business, An...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Data Mining, HTML, Data Analytics, SQL, Postg...</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>155000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Sr, Data, Scientist, , ProServe, GenAI, , , O...</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>CA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>20000</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>[About, the, job, you, looking, to, work, at, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Machine Learning, Artificial Intelligence (AI...</td>\n",
       "      <td>127300.0</td>\n",
       "      <td>247600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Data, Scientist]</td>\n",
       "      <td>Insight Global</td>\n",
       "      <td>WA</td>\n",
       "      <td>Contract</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>3000</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>[About, the, job, Data, Scientist, Hardware, a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Python (Programming Language), Applied Machin...</td>\n",
       "      <td>145600.0</td>\n",
       "      <td>166400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>[Mission, Solution, SAFe, Shared, Services, , ...</td>\n",
       "      <td>CACI International Inc</td>\n",
       "      <td>CO</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>20000</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>[About, the, job, Job, Category, Type, Full, C...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[R (Programming Language), Big Data Analytics,...</td>\n",
       "      <td>104200.0</td>\n",
       "      <td>229200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>[Data, Scientist]</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>AL</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>20000</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>[About, the, job, Job, Number, Opportunity, As...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Data Mining, Analytics, Data Analytics, Panda...</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>166000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>[Data, Scientist, , Analytics, , , Tiktok]</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>CA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>20000</td>\n",
       "      <td>Entertainment Providers</td>\n",
       "      <td>[About, the, job, is, the, leading, destinatio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Data Visualization, Natural Language Processi...</td>\n",
       "      <td>144000.0</td>\n",
       "      <td>240000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>[Data, Scientist, , Mid]</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>IN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>20000</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>[About, the, job, Job, Number, Scientist, Oppo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Python (Programming Language), Analytics, Dat...</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>166000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>[Principal, Data, Scientist]</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>350</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>[About, the, job, Principal, Data, Scientist, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Python (Programming Language), SQL, Snowflake]</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Job_Title_Words  \\\n",
       "0    [Data, Scientist, II, , Amazon, Business, Ops,...   \n",
       "1                                    [Data, Scientist]   \n",
       "2         [Data, Scientist, with, Security, Clearance]   \n",
       "3    [Sr, Data, Scientist, , ProServe, GenAI, , , O...   \n",
       "4                                    [Data, Scientist]   \n",
       "..                                                 ...   \n",
       "616  [Mission, Solution, SAFe, Shared, Services, , ...   \n",
       "617                                  [Data, Scientist]   \n",
       "618         [Data, Scientist, , Analytics, , , Tiktok]   \n",
       "619                           [Data, Scientist, , Mid]   \n",
       "620                       [Principal, Data, Scientist]   \n",
       "\n",
       "                  Company_Name State   Job_Type   Remote  Experience_Level  \\\n",
       "0                       Amazon    VA  Full-time  Unknown  Mid-Senior level   \n",
       "1       CACI International Inc    CO  Full-time  Unknown  Mid-Senior level   \n",
       "2                ClearanceJobs    VA  Full-time   Hybrid  Mid-Senior level   \n",
       "3    Amazon Web Services (AWS)    CA  Full-time  Unknown  Mid-Senior level   \n",
       "4               Insight Global    WA   Contract  On-site  Mid-Senior level   \n",
       "..                         ...   ...        ...      ...               ...   \n",
       "616     CACI International Inc    CO  Full-time  On-site  Mid-Senior level   \n",
       "617        Booz Allen Hamilton    AL  Full-time  Unknown           Unknown   \n",
       "618                     TikTok    CA  Full-time  Unknown           Unknown   \n",
       "619        Booz Allen Hamilton    IN  Full-time  Unknown           Unknown   \n",
       "620                    Harnham    AZ  Full-time   Hybrid  Mid-Senior level   \n",
       "\n",
       "     Company_Size                            Field  \\\n",
       "0           20000             Software Development   \n",
       "1           20000    IT Services and IT Consulting   \n",
       "2              30  Defense and Space Manufacturing   \n",
       "3           20000    IT Services and IT Consulting   \n",
       "4            3000          Staffing and Recruiting   \n",
       "..            ...                              ...   \n",
       "616         20000    IT Services and IT Consulting   \n",
       "617         20000    IT Services and IT Consulting   \n",
       "618         20000          Entertainment Providers   \n",
       "619         20000    IT Services and IT Consulting   \n",
       "620           350          Staffing and Recruiting   \n",
       "\n",
       "                                 Job_Description_Words Posted_Skills  \\\n",
       "0    [About, the, job, are, seeking, a, Data, Scien...            []   \n",
       "1    [About, the, job, Job, Category, Type, Full, C...            []   \n",
       "2    [About, the, job, Award, Winning, Business, An...            []   \n",
       "3    [About, the, job, you, looking, to, work, at, ...            []   \n",
       "4    [About, the, job, Data, Scientist, Hardware, a...            []   \n",
       "..                                                 ...           ...   \n",
       "616  [About, the, job, Job, Category, Type, Full, C...            []   \n",
       "617  [About, the, job, Job, Number, Opportunity, As...            []   \n",
       "618  [About, the, job, is, the, leading, destinatio...            []   \n",
       "619  [About, the, job, Job, Number, Scientist, Oppo...            []   \n",
       "620  [About, the, job, Principal, Data, Scientist, ...            []   \n",
       "\n",
       "                                     Associated_Skills  Salary_Lower  \\\n",
       "0    [Machine Learning, Extract, Transform, Load (E...      111600.0   \n",
       "1    [Logistic Regression, Computer Vision, Machine...       82100.0   \n",
       "2    [Data Mining, HTML, Data Analytics, SQL, Postg...      155000.0   \n",
       "3    [Machine Learning, Artificial Intelligence (AI...      127300.0   \n",
       "4    [Python (Programming Language), Applied Machin...      145600.0   \n",
       "..                                                 ...           ...   \n",
       "616  [R (Programming Language), Big Data Analytics,...      104200.0   \n",
       "617  [Data Mining, Analytics, Data Analytics, Panda...       73000.0   \n",
       "618  [Data Visualization, Natural Language Processi...      144000.0   \n",
       "619  [Python (Programming Language), Analytics, Dat...       73000.0   \n",
       "620    [Python (Programming Language), SQL, Snowflake]      130000.0   \n",
       "\n",
       "     Salary_Upper  \n",
       "0        212800.0  \n",
       "1        172400.0  \n",
       "2        155000.0  \n",
       "3        247600.0  \n",
       "4        166400.0  \n",
       "..            ...  \n",
       "616      229200.0  \n",
       "617      166000.0  \n",
       "618      240000.0  \n",
       "619      166000.0  \n",
       "620      140000.0  \n",
       "\n",
       "[621 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Job_Title_Words','Company_Name','State','Job_Type','Remote','Experience_Level','Company_Size','Field', 'Job_Description_Words','Posted_Skills','Associated_Skills' ,'Salary_Lower','Salary_Upper']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f57c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9361f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc59555f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
