{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "22782e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyautogui\n",
    "import urllib.parse\n",
    "import time\n",
    "import pyperclip\n",
    "import quopri\n",
    "from bs4 import BeautifulSoup\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "import requests\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ee5d9",
   "metadata": {},
   "source": [
    "# 1.Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e158b05b",
   "metadata": {},
   "source": [
    "#### (1). Download LinkedIn Search Results Webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d7337a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an automatic process to download the job search pages in Linkedin\n",
    "def auto_download_search(url,file_name):\n",
    "    pyautogui.hotkey('ctrl', '2') # switch Google Chrome tabs\n",
    "    time.sleep(1)\n",
    "    \n",
    "    pyautogui.click(207,55) # click the browser's address bar.\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    pyautogui.hotkey('ctrl', 'a') # select all content in the address bar.\n",
    "    pyperclip.copy(url) # copy the url\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    pyautogui.hotkey('ctrl', 'v') # paste the url\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    pyautogui.hotkey('enter') # access the url\n",
    "    time.sleep(10)\n",
    "    \n",
    "    pyautogui.click(882,1023)\n",
    "    pyautogui.mouseDown() # scroll down the page to look through all job posts\n",
    "    time.sleep(10)\n",
    "    pyautogui.mouseUp()# release the left mouse button\n",
    "    \n",
    "    pyautogui.hotkey('ctrl', 's') # save the page to local path\n",
    "    time.sleep(2)\n",
    "    pyperclip.copy(file_name) # copy the file name\n",
    "    pyautogui.hotkey('ctrl', 'v') # paste the file name\n",
    "    time.sleep(2)\n",
    "    pyautogui.hotkey('enter') # save the page with given name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430ed6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a process to look through all the pages of search results\n",
    "def search_page_download():\n",
    "    for i in range(0,1000,25):\n",
    "        url = f\"https://www.linkedin.com/jobs/search/?currentJobId=3733476715&f_SB2=1&f_TPR=r2592000&geoId=103644278&keywords=data%20scientist&location=United%20States&origin=JOB_SEARCH_PAGE_JOB_FILTER&refresh=true&sortBy=R&spellCorrectionEnabled=true&start={i}\"\n",
    "        file_name = f\"data_science_job_{int(i/25)}.mhtml\"\n",
    "        auto_download_search(url, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bb42a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download all pages to collect 1000 job posts related to data science\n",
    "search_page_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a54abc",
   "metadata": {},
   "source": [
    "(2). Extract Individual Job Post URLs from LinkedIn Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "b0f4a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract urls of job posts from all the pages\n",
    "def job_url(file_path):\n",
    "    urls = []\n",
    "    # Open the MHTML file in binary mode and parse it\n",
    "    with open(file_path, 'rb') as file:\n",
    "        msg = BytesParser(policy=policy.default).parse(file)\n",
    "\n",
    "    # Decode the HTML part correctly\n",
    "    html_part = None\n",
    "    for part in msg.walk():\n",
    "        content_type = part.get_content_type()\n",
    "        if content_type == 'text/html':\n",
    "            html_part = part.get_payload(decode=True)\n",
    "            break\n",
    "    \n",
    "    # parse the HTML\n",
    "    charset = 'utf-8'\n",
    "    decoded_html = html_part.decode(charset)\n",
    "    soup = BeautifulSoup(decoded_html, 'html.parser')\n",
    "    jobs = soup.find(class_ = \"scaffold-layout__list-container\")\n",
    "    job_info = jobs.find_all(class_ = \"disabled ember-view job-card-container__link job-card-list__title\")\n",
    "    # extract the url for each job post\n",
    "    for i in job_info:\n",
    "        url = i['href']\n",
    "        urls.append(url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "43066379",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "job_urls = {}\n",
    "i = 0\n",
    "path = \"D:/Study Abroad/course/DSCI441/project/webpages\"\n",
    "\n",
    "# get the urls of all job posts from the local job pages\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        urls = job_url(file_path)\n",
    "        for url in urls:\n",
    "            job_urls[i] = {}\n",
    "            job_urls[i][\"url\"] = url\n",
    "            job_urls[i][\"status\"] = 0\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ad7da",
   "metadata": {},
   "source": [
    "(3). Download Job Post Details Webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "388fe551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually login the linkedin website\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.linkedin.com/home\")\n",
    "\n",
    "# wait enough time to log in manually\n",
    "time.sleep(20)  \n",
    "\n",
    "# save the cookies to a file after login\n",
    "pickle.dump(driver.get_cookies(), open(\"D:/Study Abroad/course/DSCI441/project/cookies.pkl\", \"wb\"))\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c56ea62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use selenium webdriver to iterate all the job pages\n",
    "# set the options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# load the previously saved cookies\n",
    "cookies = pickle.load(open(\"D:/Study Abroad/course/DSCI441/project/cookies.pkl\", \"rb\"))\n",
    "\n",
    "# iterate all job post pages and download them to local path\n",
    "for i in range(0,1000):\n",
    "    index = i\n",
    "    value = job_urls[index]\n",
    "    \n",
    "    # open a new driver after iterating the job post pages for 20 times in order to save memory\n",
    "    if index % 20 == 0:\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(\"https://www.linkedin.com/home\")\n",
    "        time.sleep(4)\n",
    "        \n",
    "        # load the cookies to the driver\n",
    "        for cookie in cookies:\n",
    "            driver.add_cookie(cookie)\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # get the url for job post\n",
    "    url = value[\"url\"]\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # use the aria-label to locate the button\n",
    "    button_aria_label = \"Click to see more description\"\n",
    "    try:\n",
    "        # Wait up to 10 seconds for the button to be clickable\n",
    "        button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, f\"//button[@aria-label='{button_aria_label}']\")))\n",
    "        # click the button \"Show More\" to show the entire job description\n",
    "        button.click()\n",
    "        \n",
    "        time.sleep(2) # wait up for all information displayed\n",
    "        \n",
    "    except Exception as e:\n",
    "        break # if failed, jump to the next iteration\n",
    "    \n",
    "    pyautogui.hotkey('ctrl', 's') # save the page to local path\n",
    "    time.sleep(2)\n",
    "    \n",
    "    file_name = \"data_scientist_job_post_\" + str(index)\n",
    "    pyperclip.copy(file_name) # copy the file name\n",
    "    \n",
    "    pyautogui.hotkey('ctrl', 'v') # paste the file name\n",
    "    time.sleep(2)\n",
    "    \n",
    "    if index % 20 == 0:\n",
    "        pyautogui.hotkey('tab')  # select the save type\n",
    "        time.sleep(1)\n",
    "\n",
    "        pyautogui.hotkey('down')\n",
    "        time.sleep(1)\n",
    "\n",
    "        pyautogui.hotkey('up')  # save file to mhtml\n",
    "        time.sleep(1)\n",
    "\n",
    "        pyautogui.hotkey('enter') # confirm the file tyep\n",
    "        time.sleep(1)\n",
    "    \n",
    "    pyautogui.hotkey('enter') # save\n",
    "    time.sleep(np.random.randint(1,4)) # wait for random time\n",
    "    \n",
    "    if index % 20 == 19:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1e598",
   "metadata": {},
   "source": [
    "(4). Extract Key Information from Job Posting Webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3ba830fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize all job_type, remote, and experience\n",
    "JOB_TYPE = [\"Full-time\",\"Part-time\",\"Contract\",\"Temporary\",\"Internship\",\"Other\"]\n",
    "REMOTE_TYPE = [\"On-site\",\"Remote\",\"Hybrid\"]\n",
    "EXPERIENCE_TYPE = [\"Internship\",\"Entry level\",\"Associate\",\"Mid-Senior level\",\"Director\",\"Executive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1d0907e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to extract job_type, remote, and experience information\n",
    "def extract_info(info, options):\n",
    "    for i in options:\n",
    "        if i in info:\n",
    "            return i\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "41dab625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables to store the details of all the jobs\n",
    "indice = []\n",
    "titles = []\n",
    "companies = []\n",
    "locations = []\n",
    "job_types = []\n",
    "remotes = []\n",
    "experiences = []\n",
    "salaries = []\n",
    "company_sizes = []\n",
    "fields = []\n",
    "job_descriptions = []\n",
    "skills_posted = []\n",
    "skills_associated = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "1f645d32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the urls of all job posts from the local job pages\n",
    "path = \"D:/Study Abroad/course/DSCI441/project/jobposts\"\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        # Open the MHTML file in binary mode and parse it\n",
    "        with open(file_path, 'rb') as file:\n",
    "            msg = BytesParser(policy=policy.default).parse(file)\n",
    "\n",
    "        # Decode the HTML part correctly\n",
    "        html_part = None\n",
    "        for part in msg.walk():\n",
    "            content_type = part.get_content_type()\n",
    "            if content_type == 'text/html':\n",
    "                html_part = part.get_payload(decode=True)\n",
    "                break\n",
    "\n",
    "        # parse the HTML\n",
    "        charset = 'utf-8'\n",
    "        decoded_html = html_part.decode(charset)\n",
    "        soup = BeautifulSoup(decoded_html, 'html.parser')\n",
    "        \n",
    "        # extract the index\n",
    "        index = file_path.replace(\".mhtml\",\"\").split(\"_\")[-1]\n",
    "        indice.append(index)\n",
    "        \n",
    "        # extract title\n",
    "        title = soup.find(class_=\"t-24 t-bold job-details-jobs-unified-top-card__job-title\").contents[0].strip()\n",
    "        titles.append(title)\n",
    "        \n",
    "        # extract company and location\n",
    "        company_location = soup.find(class_=\"job-details-jobs-unified-top-card__primary-description-without-tagline mb2\").text.strip()\n",
    "        company = company_location.split('·')[0].strip()\n",
    "        location = company_location.split('·')[1].strip()\n",
    "        companies.append(company)\n",
    "        locations.append(location)\n",
    "        \n",
    "        # extract job_type, remote, experience, and salary\n",
    "        salary_jobtype_Remote_Experience = soup.find(class_=\"job-details-jobs-unified-top-card__job-insight job-details-jobs-unified-top-card__job-insight--highlight\").text\n",
    "        job_type = extract_info(salary_jobtype_Remote_Experience,JOB_TYPE)\n",
    "        remote = extract_info(salary_jobtype_Remote_Experience,REMOTE_TYPE)\n",
    "        experience = extract_info(salary_jobtype_Remote_Experience,EXPERIENCE_TYPE)\n",
    "        salary = salary_jobtype_Remote_Experience.strip().split('\\n')[0]\n",
    "        job_types.append(job_type)\n",
    "        remotes.append(remote)\n",
    "        experiences.append(experience)\n",
    "        salaries.append(salary)\n",
    "        \n",
    "        # extract company size and field\n",
    "        companysize_field = soup.find_all(class_ = \"job-details-jobs-unified-top-card__job-insight\")[1].text.split('·')\n",
    "        company_size = companysize_field[0].strip()\n",
    "        company_sizes.append(company_size)\n",
    "        if len(companysize_field)>1: \n",
    "            field = companysize_field[1].strip() \n",
    "        else:\n",
    "            field = None\n",
    "        fields.append(field)\n",
    "        \n",
    "        # extract the job description\n",
    "        job_description = soup.find(class_ = \"jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch\").text.strip()\n",
    "        job_descriptions.append(job_description)\n",
    "\n",
    "        # extract the associated skills and skills added by job posters\n",
    "        skill_posted = [item.text for item in soup.find_all(class_=\"pt5\")[1].find_all(\"a\",class_=\"app-aware-link job-details-how-you-match__skills-item-subtitle t-14 overflow-hidden\")]\n",
    "        skill_associated = [item.text for item in soup.find_all(class_=\"pt5\")[1].find_all(\"a\",class_=\"app-aware-link job-details-how-you-match__skills-section-descriptive-skill t-14\")]\n",
    "        skills_posted.append(skill_posted)\n",
    "        skills_associated.append(skill_associated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "011a3fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job_Type</th>\n",
       "      <th>Remote</th>\n",
       "      <th>Experience_Level</th>\n",
       "      <th>salary</th>\n",
       "      <th>Company_Size</th>\n",
       "      <th>Field</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>Posted_Skills</th>\n",
       "      <th>Associated_Skills</th>\n",
       "      <th>Files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Globant</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$60/hr - $70/hr</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>About the job\\n            \\n \\nHigh familiari...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Business Development · Cold Calling · Custome...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>The Brite Group Incorporated</td>\n",
       "      <td>Herndon, VA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>None</td>\n",
       "      <td>$100,000/yr - $135,000/yr</td>\n",
       "      <td>51-200 employees</td>\n",
       "      <td>None</td>\n",
       "      <td>About the job\\n            \\n \\nSkills Require...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Artificial Intelligence (AI) · Data Science ·...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>RVO Health</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>$94,400/yr - $120,000/yr</td>\n",
       "      <td>1,001-5,000 employees</td>\n",
       "      <td>Hospitals and Health Care</td>\n",
       "      <td>About the job\\n            \\n \\nAT A GLANCEWe ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Machine Learning · R (Programming Language) ·...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist, Mid</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>Alexandria, VA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>$93,300/yr - $212,000/yr</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>About the job\\n            \\n \\nJob Number: R0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Natural Language Processing (NLP) · Statistic...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist, SEO</td>\n",
       "      <td>Grammarly</td>\n",
       "      <td>Virginia, United States</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$181,000/yr - $281,000/yr</td>\n",
       "      <td>1,001-5,000 employees</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>About the job\\n            \\n \\nGrammarly is e...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Problem Solving · Predictive Analytics · R (P...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Data Scientist, Mid</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>$73,100/yr - $166,000/yr</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>About the job\\n            \\n \\nJob Number: R0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Data Mining · Pattern Recognition · Data Clea...</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Principal Data Scientist - BCG X &amp; BCG Fed</td>\n",
       "      <td>BCG X</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>None</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$252,900/yr</td>\n",
       "      <td>1,001-5,000 employees</td>\n",
       "      <td>Business Consulting and Services</td>\n",
       "      <td>About the job\\n            \\n \\nWho We AreBost...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Data Visualization · Pattern Recognition · St...</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>The Walt Disney Company</td>\n",
       "      <td>Santa Monica, CA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$136,038/yr - $182,490/yr</td>\n",
       "      <td>10,001+ employees</td>\n",
       "      <td>Entertainment Providers</td>\n",
       "      <td>About the job\\n            \\n \\nThe Walt Disne...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Data Analytics · Analytics · Mathematics · Da...</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Data Scientist | AI Products</td>\n",
       "      <td>Red Ventures</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>$80,000/yr - $150,000/yr</td>\n",
       "      <td>1,001-5,000 employees</td>\n",
       "      <td>Technology, Information and Internet</td>\n",
       "      <td>About the job\\n            \\n \\nWe are looking...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Machine Learning · Problem Solving · Python (...</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Senior/Staff Data Scientist - Collision Avoida...</td>\n",
       "      <td>Zoox</td>\n",
       "      <td>Foster City, CA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>$210,000/yr - $300,000/yr</td>\n",
       "      <td>1,001-5,000 employees</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>About the job\\n            \\n \\nThe Collision ...</td>\n",
       "      <td>[Data Science, Pattern Recognition, Performanc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Job_Title  \\\n",
       "0                                       Data Scientist   \n",
       "1                                       Data Scientist   \n",
       "2                                       Data Scientist   \n",
       "3                                  Data Scientist, Mid   \n",
       "4                                  Data Scientist, SEO   \n",
       "..                                                 ...   \n",
       "995                                Data Scientist, Mid   \n",
       "996         Principal Data Scientist - BCG X & BCG Fed   \n",
       "997                              Senior Data Scientist   \n",
       "998                       Data Scientist | AI Products   \n",
       "999  Senior/Staff Data Scientist - Collision Avoida...   \n",
       "\n",
       "                     Company_Name                 Location   Job_Type  \\\n",
       "0                         Globant              Orlando, FL   Contract   \n",
       "1    The Brite Group Incorporated              Herndon, VA  Full-time   \n",
       "2                      RVO Health          Minneapolis, MN  Full-time   \n",
       "3             Booz Allen Hamilton           Alexandria, VA  Full-time   \n",
       "4                       Grammarly  Virginia, United States  Full-time   \n",
       "..                            ...                      ...        ...   \n",
       "995           Booz Allen Hamilton            San Diego, CA  Full-time   \n",
       "996                         BCG X               Boston, MA  Full-time   \n",
       "997       The Walt Disney Company         Santa Monica, CA  Full-time   \n",
       "998                  Red Ventures            Charlotte, NC  Full-time   \n",
       "999                          Zoox          Foster City, CA  Full-time   \n",
       "\n",
       "      Remote  Experience_Level                     salary  \\\n",
       "0     Remote  Mid-Senior level            $60/hr - $70/hr   \n",
       "1     Hybrid              None  $100,000/yr - $135,000/yr   \n",
       "2     Hybrid       Entry level   $94,400/yr - $120,000/yr   \n",
       "3       None              None   $93,300/yr - $212,000/yr   \n",
       "4     Hybrid  Mid-Senior level  $181,000/yr - $281,000/yr   \n",
       "..       ...               ...                        ...   \n",
       "995     None              None   $73,100/yr - $166,000/yr   \n",
       "996     None  Mid-Senior level                $252,900/yr   \n",
       "997  On-site  Mid-Senior level  $136,038/yr - $182,490/yr   \n",
       "998   Hybrid       Entry level   $80,000/yr - $150,000/yr   \n",
       "999   Hybrid  Mid-Senior level  $210,000/yr - $300,000/yr   \n",
       "\n",
       "              Company_Size                                 Field  \\\n",
       "0        10,001+ employees         IT Services and IT Consulting   \n",
       "1         51-200 employees                                  None   \n",
       "2    1,001-5,000 employees             Hospitals and Health Care   \n",
       "3        10,001+ employees         IT Services and IT Consulting   \n",
       "4    1,001-5,000 employees                  Software Development   \n",
       "..                     ...                                   ...   \n",
       "995      10,001+ employees         IT Services and IT Consulting   \n",
       "996  1,001-5,000 employees      Business Consulting and Services   \n",
       "997      10,001+ employees               Entertainment Providers   \n",
       "998  1,001-5,000 employees  Technology, Information and Internet   \n",
       "999  1,001-5,000 employees                            Automotive   \n",
       "\n",
       "                                       Job_Description  \\\n",
       "0    About the job\\n            \\n \\nHigh familiari...   \n",
       "1    About the job\\n            \\n \\nSkills Require...   \n",
       "2    About the job\\n            \\n \\nAT A GLANCEWe ...   \n",
       "3    About the job\\n            \\n \\nJob Number: R0...   \n",
       "4    About the job\\n            \\n \\nGrammarly is e...   \n",
       "..                                                 ...   \n",
       "995  About the job\\n            \\n \\nJob Number: R0...   \n",
       "996  About the job\\n            \\n \\nWho We AreBost...   \n",
       "997  About the job\\n            \\n \\nThe Walt Disne...   \n",
       "998  About the job\\n            \\n \\nWe are looking...   \n",
       "999  About the job\\n            \\n \\nThe Collision ...   \n",
       "\n",
       "                                         Posted_Skills  \\\n",
       "0                                                   []   \n",
       "1                                                   []   \n",
       "2                                                   []   \n",
       "3                                                   []   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "995                                                 []   \n",
       "996                                                 []   \n",
       "997                                                 []   \n",
       "998                                                 []   \n",
       "999  [Data Science, Pattern Recognition, Performanc...   \n",
       "\n",
       "                                     Associated_Skills Files  \n",
       "0    [Business Development · Cold Calling · Custome...     0  \n",
       "1    [Artificial Intelligence (AI) · Data Science ·...     1  \n",
       "2    [Machine Learning · R (Programming Language) ·...    10  \n",
       "3    [Natural Language Processing (NLP) · Statistic...   100  \n",
       "4    [Problem Solving · Predictive Analytics · R (P...   101  \n",
       "..                                                 ...   ...  \n",
       "995  [Data Mining · Pattern Recognition · Data Clea...   995  \n",
       "996  [Data Visualization · Pattern Recognition · St...   996  \n",
       "997  [Data Analytics · Analytics · Mathematics · Da...   997  \n",
       "998  [Machine Learning · Problem Solving · Python (...   998  \n",
       "999                                                 []   999  \n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame((titles,companies,locations,job_types,remotes,experiences,salaries,company_sizes,fields,job_descriptions,skills_posted,skills_associated,indice)).T\n",
    "df.columns=[\"Job_Title\",\"Company_Name\",\"Location\",\"Job_Type\",\"Remote\",\"Experience_Level\",\"salary\",\"Company_Size\",\"Field\",\"Job_Description\",\"Posted_Skills\",\"Associated_Skills\",\"Files\"]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
